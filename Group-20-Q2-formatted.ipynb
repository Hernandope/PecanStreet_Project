{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Initializations\n",
    "\n",
    "### Note: This document cannot be converted to pdf due to the presence of plotly graphs which require a paid subscription for the pdf service. Instead, please view the .html version of the document. The graphs are interactive - try hovering your mouse over points on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import numpy as np\n",
    "\n",
    "# Done to avoid flooding the screen with warnings for legacy numpy operations\n",
    "# in pandas methods\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes quite a bit of time for date-inference\n",
    "# Optimization: Consider manual caching in a dict (top StOvflw answer)\n",
    "data = pd.read_csv(\"dataport-export_gas_oct2015-mar2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localminute</th>\n",
       "      <th>dataid</th>\n",
       "      <th>meter_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-01 00:00:10-05</td>\n",
       "      <td>739</td>\n",
       "      <td>88858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-01 00:00:13-05</td>\n",
       "      <td>8890</td>\n",
       "      <td>197164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-01 00:00:20-05</td>\n",
       "      <td>6910</td>\n",
       "      <td>179118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-01 00:00:22-05</td>\n",
       "      <td>3635</td>\n",
       "      <td>151318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-01 00:00:22-05</td>\n",
       "      <td>1507</td>\n",
       "      <td>390354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              localminute  dataid  meter_value\n",
       "0  2015-10-01 00:00:10-05     739        88858\n",
       "1  2015-10-01 00:00:13-05    8890       197164\n",
       "2  2015-10-01 00:00:20-05    6910       179118\n",
       "3  2015-10-01 00:00:22-05    3635       151318\n",
       "4  2015-10-01 00:00:22-05    1507       390354"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data to make sure the read was successful.\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: localminute column is clean and error free\n",
    "def index_and_sort(data): \n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    for k,df in data.groupby([\"dataid\"]): \n",
    "        df.sort_values(by=[\"localminute\"], inplace=True)\n",
    "        df[\"val_diff\"] = df[\"meter_value\"].diff()\n",
    "\n",
    "        df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df['localminute'], utc=True, infer_datetime_format=True, cache=True)))\n",
    "        df.drop(columns=[\"localminute\"], inplace=True)\n",
    "        \n",
    "        merged_df = merged_df.append(df)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from question 1, used to remove irregular spikes in meter value reading\n",
    "def remove_spikes(data_df): \n",
    "    spikeless_resampled_df = pd.DataFrame()\n",
    "\n",
    "    for k, df in data_df.groupby(\"dataid\"): \n",
    "        spikeless_df = df[~(df['val_diff'].shift(-1) < 0)] \n",
    "        spikeless_df['val_diff'] = spikeless_df['meter_value'].diff()\n",
    "\n",
    "        # Need to do this because some spikes are less \"sharp\" than 1 timestemp\n",
    "        for i in range(10):  # by right should be doing UNTIL no more spikes left. Tested to see no more spikes after 10 passes\n",
    "            spikeless_df = spikeless_df[~(spikeless_df['val_diff'].shift(-1) < 0)] \n",
    "            spikeless_df['val_diff'] = spikeless_df['meter_value'].diff()\n",
    "\n",
    "        spikeless_sample = spikeless_df.resample('1h').mean()\n",
    "        spikeless_sample[\"dataid\"].fillna(k, inplace=True)\n",
    "        spikeless_sample[\"meter_value\"] = spikeless_sample[\"meter_value\"].interpolate()\n",
    "        spikeless_resampled_df = spikeless_resampled_df.append(spikeless_sample)\n",
    "\n",
    "    return spikeless_resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing df into inputs ready for training\n",
    "# input frame = [LOOKBACK_PERIOD val_diffs] + [ExpectedOutput] + [HourToPredictFor]\n",
    "# returns: [inputs], [labels] where correspond by position\n",
    "def make_io_frames(data_df): \n",
    "    input_data = []\n",
    "    for k, df in data_df.groupby('dataid'): \n",
    "        diff_series =  df['meter_value'].diff().dropna()\n",
    "\n",
    "        # The = + [] is giving the model the hour of day it is predicting for (important)  \n",
    "        list_of_data = [diff_series[i:i+LOOKBACK_PERIOD+1].tolist() + [diff_series[i:i+LOOKBACK_PERIOD+1].index[-1].hour] for i in range(0,df.shape[0],1) if diff_series[i:i+LOOKBACK_PERIOD+1].shape[0] == LOOKBACK_PERIOD+1]\n",
    "\n",
    "        for item in list_of_data: \n",
    "            input_data.append(item)\n",
    "   \n",
    "    X = [frame[:LOOKBACK_PERIOD]+[frame[-1]] for frame in input_data]\n",
    "    Y = [frame[-2] for frame in input_data]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the frontend for the model that preprocesses input_data before  \n",
    "\n",
    "# Assumptions: \n",
    "# input_data contain all data points for the past LOOKBACK+1 hours.\n",
    "# input data has a DateTimeIndex\n",
    "# input data is sorted \n",
    "# hour_to_predict is a pandas_timestamp. \n",
    "def predict(input_data, hour_to_predict, model): \n",
    "\n",
    "    latest_available_reading = input_data[input_data.index < hour_to_predict].meter_value[-1]\n",
    "\n",
    "    #print(input_data)\n",
    "    #print(\"Predicting for\", hour_to_predict)\n",
    "\n",
    "    meter_readings = input_data['meter_value']\n",
    "    meter_readings = meter_readings[(meter_readings.index > (hour_to_predict - pd.Timedelta(str(LOOKBACK_PERIOD)+'h'))) & (meter_readings.index < hour_to_predict)]\n",
    "    meter_readings = meter_readings.resample('1h').mean()\n",
    "\n",
    "    #print(meter_readings)\n",
    "\n",
    "    def getMeterReading(hours_prior):\n",
    "        req_hour = hour_to_predict - pd.Timedelta(str(hours_prior)+'h')\n",
    "        #print(req_hour)\n",
    "        if req_hour in meter_readings.index:\n",
    "            return meter_readings.loc[req_hour]\n",
    "        return np.nan\n",
    "\n",
    "    attributes = pd.Series([getMeterReading(i) for i in range(LOOKBACK_PERIOD+1, 0, -1)])\n",
    "    attributes = attributes.interpolate()\n",
    "    #print(attributes)\n",
    "\n",
    "    diffs = attributes.diff().fillna(0)[1:]\n",
    "    #print(diffs)\n",
    "    \n",
    "    prediction = model.predict([diffs.tolist() + [hour_to_predict.hour]])\n",
    "\n",
    "    return latest_available_reading + prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a house, SIMULATE day to day predictions \n",
    "# Take last LOOKBACK PERIOD readings and simulating next hour (time t)\n",
    "# After actual reading of time t is found, repeat for time t+1. \n",
    "# until last known data point. \n",
    "# NOTE: Inherent correction in prediction graph. \n",
    "def simulate_operation(df_for_house, model):\n",
    "\n",
    "    timestamps_to_predict_for = df_for_house\n",
    "    timestamps_to_predict_for = timestamps_to_predict_for.resample('1h').last()\n",
    "    timestamps = (timestamps_to_predict_for.index)[LOOKBACK_PERIOD+1:]\n",
    "\n",
    "    predictions = []\n",
    "    predicted_timestamps = []\n",
    "\n",
    "    for time in timestamps: \n",
    "        try: \n",
    "            predictions.append(predict(df_for_house, time, model))\n",
    "            predicted_timestamps.append(time)\n",
    "        except: \n",
    "            print(\"ERROR PREDICTING \", time)\n",
    "\n",
    "    return predicted_timestamps, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a house, SIMULATE day to day predictions \n",
    "# Take last LOOKBACK PERIOD readings and simulating next hour (time t)\n",
    "# assume prediction is correct, repeat for time t+1. \n",
    "# NOTE: Long term predicting over predictions. \n",
    "def long_term_prediction(df_for_house, time_start, num_days_to_predict, model):\n",
    "\n",
    "    seed_data = df_for_house[df_for_house.index < time_start]\n",
    "    seed_data.drop(columns=['val_diff', 'dataid'], inplace=True)\n",
    "\n",
    "    timestamps = pd.date_range(time_start, periods=num_days_to_predict*24, freq='H')\n",
    "\n",
    "    predictions = []\n",
    "    predicted_timestamps = []\n",
    "\n",
    "    for time in timestamps: \n",
    "\n",
    "        try:\n",
    "            prediction = predict(seed_data, time, model)\n",
    "            predictions.append(prediction)\n",
    "            seed_data = seed_data.append(pd.DataFrame(data=[prediction], columns=['meter_value'], index=[time]))\n",
    "            predicted_timestamps.append(time)\n",
    "            #print(seed_data)\n",
    "        except: \n",
    "            print(\"ERROR PREDICTING\", time)\n",
    "\n",
    "    return predicted_timestamps, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how model does on mean data. \n",
    "def mean_readings_for_area(df): \n",
    "    mean_data = df.resample('1h').mean() # get mean val_diffs\n",
    "    mean_data['meter_value'] = mean_data['val_diff'].cumsum()   # simulate meter_readings from mean_val_diffs\n",
    "    return mean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1\n",
    "\n",
    "## Question 2.1 (a) \n",
    "\n",
    "In this part, you will asked to build a model to forecast the hourly readings in the future (next hour). \n",
    "\n",
    "1. Can you explain why you may want to forecast the gas consumption in the future? Who would find this information valuable? \n",
    "2. What can you do if you have a good forecasting model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As one of the fundamental driving forces of economic activities of the world, energy is a crucial consideration in many key decision making processes. Due to its non-renewable nature, and rapidly increasing demand, it is important to use fossil fuels as efficient as possible. Despite falling on the category of fossil fuels, natural gas combustion emits less greenhouse gas and places it as a cleaner and safer option as compared to other fossil fuels such as coal or oil.\n",
    "\n",
    "A good forecasting model will be able to allow power and gas utility supplier companies to predict periods for which a certain area would experience higher increase in demand. Subsequently, accurate underground stock optimization would allow companies to prevent overstock, which would prove to be costly as the unusable gas would still need to be paid due to contractual agreement. In addition, the prevention of under stocking is also highly important to prevent downtimes and other catastrophic repercussions from inability to meet demand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "\n",
    "Build a linear regression model to forecast the hourly readings in the future (next hour). \n",
    "\n",
    "Generate two plots: \n",
    "\n",
    "**1. Time series plot of the actual and predicted hourly meter readings**\n",
    "\n",
    "**2. Scatter plot of actual vs predicted meter readings (along with the line showing how good the fit is)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read CSV data\n",
    "# Takes quite a bit of time for date-inference\n",
    "# Optimization: Consider manual caching in a dict (top StOvflw answer)\n",
    "data = pd.read_csv(\"dataport-export_gas_oct2015-mar2016.csv\")\n",
    "merged_df = index_and_sort(data)\n",
    "clean_df = remove_spikes(merged_df)\n",
    "\n",
    "X, Y = make_io_frames(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tunable Hyper-Parameter:  \n",
    "LOOKBACK_PERIOD = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (a) - Time series plot of the actual and predicted hourly meter readings with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create linear regresison model and train\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take predictions of linear regression models\n",
    "predictions = lin_model.predict(X_train)\n",
    "# Example of how to use model:\n",
    "# predict(merged_df[:50], pd.Timestamp('2015-10-04 17:00:00+00:00'), lin_model)\n",
    "\n",
    "mean_squared_error(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate MSE in predictions train set\n",
    "predictions_test = lin_model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate MSE in predictions test set\n",
    "predictions_test = lin_model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## architecture for inference\n",
    "# raw-data -> [PreProcessing] -> [ModelFrontend] -> [Model] -> [Predictions]\n",
    "\n",
    "# if Predictions = 1 hour only and always corrected, use simulate_operation below. \n",
    "# if recursive prediction = predict over predictions, use long_term_prediction below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, predictions = simulate_operation(merged_df[merged_df['dataid'] == 35][:250], lin_model)\n",
    "ltp_timestamps, ltp_predictions = long_term_prediction(merged_df[merged_df['dataid'] == 35][:250], pd.Timestamp('2015-10-02 01:00:00+00:00'), 6, lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before plotting actual, need to take to utc because plotly doesn't do it for us.\n",
    "actual = merged_df[merged_df['dataid'] == 35][:250]\n",
    "imputed_actual = clean_df[clean_df['dataid'] == 35][:250]\n",
    "\n",
    "fig = px.scatter()\n",
    "fig.add_scatter(x=timestamps, y=predictions, name='predictions')\n",
    "fig.add_scatter(x=actual.index, y=actual['meter_value'].tolist(), name='actual')\n",
    "fig.add_scatter(x=imputed_actual.index, y=imputed_actual['meter_value'].tolist(), name='imputed')\n",
    "fig.add_scatter(x=ltp_timestamps, y=ltp_predictions, name='long_term_prediction')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be observed that the model is predicts the meter value usage ina pessimistic manner. One noticable issue with tht model is the imperfection in imputation, largely due to the fact that the input data fed into the model was imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = mean_readings_for_area(clean_df)\n",
    "mean_timestamps, mean_predictions = simulate_operation(mean_data[:250], lin_model)\n",
    "mean_ltp_timestamps, mean_ltp_predictions = long_term_prediction(mean_data[:250], pd.Timestamp('2015-10-02 01:00:00+00:00'), 6, lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = mean_data[:250]\n",
    "fig = px.scatter()\n",
    "fig.add_scatter(x=mean_timestamps, y=mean_predictions, name='predictions')\n",
    "fig.add_scatter(x=truth.index, y=truth['meter_value'].tolist(), name='mean')\n",
    "fig.add_scatter(x=mean_ltp_timestamps, y=mean_ltp_predictions, name='long_term_prediction')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model does well on \"mean\" data for the entire area. \n",
    "2. Can use this model to predict the average gas usage of the entire area over the next hour. \n",
    "3. Long Term predictions still VERY poor. \n",
    "\n",
    "Our group attempted to predict multiple hours in front in an attempt to improve the prediction but did not see any positive result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (b) - Scatter plot of actual vs predicted meter readings (along with the line showing how good the fit is) with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3\n",
    "\n",
    "Do the same as Question 2.2 above but use support vector regression (SVR).\n",
    "\n",
    "Generate two plots: \n",
    "\n",
    "**1. Time series plot of the actual and predicted hourly meter readings**\n",
    "\n",
    "**2. Scatter plot of actual vs predicted meter readings (along with the line showing how good the fit is)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (a) - Time series plot of the actual and predicted hourly meter readings with SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svr_lin = LinearSVR(verbose=True)\n",
    "svr_lin.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, predictions = simulate_operation(merged_df[merged_df['dataid'] == 35][:250], svr_lin)\n",
    "ltp_timestamps, ltp_predictions = long_term_prediction(merged_df[merged_df['dataid'] == 35][:250], pd.Timestamp('2015-10-02 01:00:00+00:00'), 6, svr_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before plotting actual, need to take to utc because plotly doesn't do it for us.\n",
    "actual = merged_df[merged_df['dataid'] == 35][:250]\n",
    "imputed_actual = clean_df[clean_df['dataid'] == 35][:250]\n",
    "\n",
    "fig = px.scatter()\n",
    "fig.add_scatter(x=timestamps, y=predictions, name='predictions')\n",
    "fig.add_scatter(x=actual.index, y=actual['meter_value'].tolist(), name='actual')\n",
    "fig.add_scatter(x=imputed_actual.index, y=imputed_actual['meter_value'].tolist(), name='imputed')\n",
    "fig.add_scatter(x=ltp_timestamps, y=ltp_predictions, name='long_term_prediction')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (b) - Scatter plot of actual vs predicted meter readings (along with the line showing how good the fit is) with SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
